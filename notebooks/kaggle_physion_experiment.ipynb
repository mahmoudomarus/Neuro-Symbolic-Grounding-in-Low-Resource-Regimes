{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSCA Physics Prior Evaluation: Predicting Stability from Initial State\n",
    "\n",
    "## The Actual Physion Task\n",
    "\n",
    "**Key insight**: The model must predict what WILL happen from the INITIAL configuration.\n",
    "It does NOT see the outcome - that's what makes this a physics reasoning task.\n",
    "\n",
    "**Previous bug**: Showing full video (including outcome) = trivially solvable.\n",
    "\n",
    "**This version**: Model sees ONLY the initial frame. Must predict: \"Will this fall?\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset: Initial State Only (No Outcome Visible)\n",
    "\n",
    "The model sees:\n",
    "- An object suspended in the air\n",
    "- A support surface (table) somewhere below\n",
    "\n",
    "The model must predict:\n",
    "- Will the object land ON the table (stable) or MISS it (unstable)?\n",
    "\n",
    "This requires understanding: \"Objects fall straight down due to gravity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysionDataset:\n",
    "    \"\"\"\n",
    "    Generate INITIAL FRAME for stability prediction.\n",
    "    Model must predict outcome WITHOUT seeing it happen.\n",
    "    \n",
    "    Physics rule: Object falls straight down. \n",
    "    Stable = object's center is above the table.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_samples: int, img_size: int = 64, seed: int = 42, difficulty: str = 'hard'):\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        \n",
    "        self.n_samples = n_samples\n",
    "        self.img_size = img_size\n",
    "        self.difficulty = difficulty\n",
    "        \n",
    "        self.images, self.labels, self.metadata = self._generate()\n",
    "        \n",
    "        # Verify balance\n",
    "        balance = self.labels.mean().item()\n",
    "        print(f\"Dataset: {n_samples} samples, {balance:.1%} stable (target: ~50%)\")\n",
    "    \n",
    "    def _generate(self):\n",
    "        images = []\n",
    "        labels = []\n",
    "        metadata = []\n",
    "        \n",
    "        # Force 50% balance\n",
    "        n_stable = self.n_samples // 2\n",
    "        n_unstable = self.n_samples - n_stable\n",
    "        targets = [1.0] * n_stable + [0.0] * n_unstable\n",
    "        np.random.shuffle(targets)\n",
    "        \n",
    "        for target in targets:\n",
    "            img, label, meta = self._generate_sample(force_stable=(target == 1.0))\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "            metadata.append(meta)\n",
    "        \n",
    "        return torch.stack(images), torch.tensor(labels).float(), metadata\n",
    "    \n",
    "    def _generate_sample(self, force_stable: bool):\n",
    "        \"\"\"Generate one initial configuration.\"\"\"\n",
    "        S = self.img_size\n",
    "        \n",
    "        # Object properties\n",
    "        obj_w = np.random.randint(8, 14)\n",
    "        obj_h = np.random.randint(6, 12)\n",
    "        obj_y = np.random.randint(5, 20)  # High up (will fall)\n",
    "        obj_color = torch.rand(3) * 0.4 + 0.5\n",
    "        \n",
    "        # Table properties  \n",
    "        table_w = np.random.randint(15, 30)\n",
    "        table_x = np.random.randint(5, S - table_w - 5)\n",
    "        table_y = S - np.random.randint(12, 20)  # Near bottom\n",
    "        table_color = torch.tensor([0.55, 0.35, 0.2])\n",
    "        \n",
    "        # Object X position determines stability\n",
    "        table_center = table_x + table_w // 2\n",
    "        \n",
    "        if force_stable:\n",
    "            # Object center must be above table\n",
    "            margin = max(2, table_w // 2 - obj_w // 2 - 2)\n",
    "            obj_center = table_center + np.random.randint(-margin, margin + 1)\n",
    "        else:\n",
    "            # Object center must NOT be above table\n",
    "            if np.random.random() < 0.5:\n",
    "                # Left of table\n",
    "                obj_center = np.random.randint(obj_w // 2 + 2, max(obj_w // 2 + 3, table_x - 2))\n",
    "            else:\n",
    "                # Right of table\n",
    "                obj_center = np.random.randint(min(table_x + table_w + 2, S - obj_w // 2 - 3), S - obj_w // 2 - 2)\n",
    "        \n",
    "        obj_x = obj_center - obj_w // 2\n",
    "        obj_x = np.clip(obj_x, 0, S - obj_w)\n",
    "        \n",
    "        # Ground truth\n",
    "        actual_center = obj_x + obj_w // 2\n",
    "        is_stable = (table_x <= actual_center <= table_x + table_w)\n",
    "        \n",
    "        # Draw frame\n",
    "        frame = torch.zeros(3, S, S)\n",
    "        \n",
    "        # Sky gradient background\n",
    "        for row in range(S):\n",
    "            frame[2, row, :] = 0.3 + 0.2 * (1 - row / S)  # Blue gradient\n",
    "            frame[0, row, :] = 0.1\n",
    "            frame[1, row, :] = 0.1\n",
    "        \n",
    "        # Draw table\n",
    "        ty1, ty2 = table_y, min(table_y + 5, S)\n",
    "        tx1, tx2 = table_x, min(table_x + table_w, S)\n",
    "        frame[:, ty1:ty2, tx1:tx2] = table_color.view(3, 1, 1)\n",
    "        \n",
    "        # Draw object\n",
    "        oy1, oy2 = obj_y, min(obj_y + obj_h, S)\n",
    "        ox1, ox2 = obj_x, min(obj_x + obj_w, S)\n",
    "        frame[:, oy1:oy2, ox1:ox2] = obj_color.view(3, 1, 1)\n",
    "        \n",
    "        # Add noise (makes pure memorization harder)\n",
    "        if self.difficulty == 'hard':\n",
    "            frame = frame + torch.randn_like(frame) * 0.03\n",
    "            frame = frame.clamp(0, 1)\n",
    "        \n",
    "        meta = {\n",
    "            'obj_center': actual_center, 'obj_x': obj_x, 'obj_w': obj_w,\n",
    "            'table_x': table_x, 'table_w': table_w,\n",
    "            'is_stable': is_stable\n",
    "        }\n",
    "        \n",
    "        return frame, 1.0 if is_stable else 0.0, meta\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "print(\"Creating datasets...\")\n",
    "train_full = PhysionDataset(n_samples=1000, seed=42)\n",
    "test_data = PhysionDataset(n_samples=300, seed=9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize samples\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "\n",
    "# Show stable examples\n",
    "stable_idx = [i for i, m in enumerate(train_full.metadata) if m['is_stable']][:5]\n",
    "for i, idx in enumerate(stable_idx):\n",
    "    axes[0, i].imshow(train_full.images[idx].permute(1, 2, 0).numpy())\n",
    "    axes[0, i].set_title(f\"STABLE\")\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "# Show unstable examples  \n",
    "unstable_idx = [i for i, m in enumerate(train_full.metadata) if not m['is_stable']][:5]\n",
    "for i, idx in enumerate(unstable_idx):\n",
    "    axes[1, i].imshow(train_full.images[idx].permute(1, 2, 0).numpy())\n",
    "    axes[1, i].set_title(f\"UNSTABLE\")\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.suptitle(\"Task: Predict if object will land on table (without seeing it fall)\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nThe model must learn: 'Objects fall straight down'\")\n",
    "print(\"If object center is above table → STABLE\")\n",
    "print(\"If object center is NOT above table → UNSTABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Models\n",
    "\n",
    "### Baseline: Pure CNN (learns everything from scratch)\n",
    "### NSCA: CNN + Physics Prior (\"objects fall straight down\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineCNN(nn.Module):\n",
    "    \"\"\"Pure neural network - must learn physics from data.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 5, stride=2, padding=2), nn.ReLU(), nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, 5, stride=2, padding=2), nn.ReLU(), nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 128, 5, stride=2, padding=2), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((2, 2))\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 * 4, 64), nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        feat = self.conv(x).flatten(1)\n",
    "        return torch.sigmoid(self.fc(feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GravityPrior(nn.Module):\n",
    "    \"\"\"\n",
    "    Physics Prior: Objects fall straight down.\n",
    "    \n",
    "    Detects:\n",
    "    1. Object position (bright region in upper half)\n",
    "    2. Table position (horizontal structure in lower half)\n",
    "    3. Predicts: Is object X-center above table?\n",
    "    \"\"\"\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        \n",
    "        # Convert to grayscale for detection\n",
    "        gray = x.mean(dim=1)  # (B, H, W)\n",
    "        \n",
    "        # Detect object (bright region in upper half)\n",
    "        upper = gray[:, :H//2, :]  # (B, H/2, W)\n",
    "        obj_mask = (upper > upper.mean(dim=(1,2), keepdim=True) + 0.1)\n",
    "        \n",
    "        # Find object center X by weighted average\n",
    "        x_coords = torch.arange(W, device=x.device).float().view(1, 1, W)\n",
    "        obj_weights = obj_mask.float() * upper\n",
    "        obj_sum = obj_weights.sum(dim=(1, 2)) + 1e-6\n",
    "        obj_center_x = (obj_weights * x_coords).sum(dim=(1, 2)) / obj_sum\n",
    "        \n",
    "        # Detect table (bright horizontal region in lower portion)\n",
    "        lower = gray[:, H*2//3:, :]  # (B, H/3, W)\n",
    "        table_mask = (lower > 0.3)  # Table is brownish, darker than object\n",
    "        \n",
    "        # Find table X range\n",
    "        table_presence = table_mask.any(dim=1).float()  # (B, W)\n",
    "        \n",
    "        # For each sample, find table left and right edges\n",
    "        results = []\n",
    "        for b in range(B):\n",
    "            tp = table_presence[b]  # (W,)\n",
    "            if tp.sum() < 3:\n",
    "                # No table detected - predict unstable\n",
    "                results.append(0.2)\n",
    "                continue\n",
    "            \n",
    "            # Find table bounds\n",
    "            table_x_coords = torch.where(tp > 0.5)[0]\n",
    "            if len(table_x_coords) == 0:\n",
    "                results.append(0.2)\n",
    "                continue\n",
    "                \n",
    "            table_left = table_x_coords.min().item()\n",
    "            table_right = table_x_coords.max().item()\n",
    "            \n",
    "            obj_x = obj_center_x[b].item()\n",
    "            \n",
    "            # Physics prediction: Is object center above table?\n",
    "            if table_left <= obj_x <= table_right:\n",
    "                # How centered? More centered = more confident\n",
    "                table_center = (table_left + table_right) / 2\n",
    "                table_half_width = (table_right - table_left) / 2 + 1e-6\n",
    "                centrality = 1.0 - abs(obj_x - table_center) / table_half_width\n",
    "                results.append(0.6 + 0.35 * centrality)  # 0.6 to 0.95\n",
    "            else:\n",
    "                # Object will miss table\n",
    "                results.append(0.15)\n",
    "        \n",
    "        return torch.tensor(results, device=x.device).view(B, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NSCAModel(nn.Module):\n",
    "    \"\"\"\n",
    "    NSCA: Neural network + Physics Prior with learnable blending.\n",
    "    \n",
    "    Key: Prior weight starts high (trust physics) but can be \n",
    "    reduced if the network finds better patterns.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, initial_prior_weight: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.cnn = BaselineCNN()\n",
    "        self.physics_prior = GravityPrior()\n",
    "        \n",
    "        # Learnable blend weight with minimum floor\n",
    "        self.min_weight = 0.2\n",
    "        # Initialize so effective weight ≈ initial_prior_weight\n",
    "        init_val = initial_prior_weight - self.min_weight\n",
    "        self._raw_weight = nn.Parameter(torch.tensor(np.log(np.exp(init_val) - 1 + 1e-6)))\n",
    "    \n",
    "    @property\n",
    "    def prior_weight(self):\n",
    "        # Soft lower bound at min_weight\n",
    "        return self.min_weight + F.softplus(self._raw_weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        learned = self.cnn(x)\n",
    "        \n",
    "        with torch.no_grad():  # Prior is not trained\n",
    "            prior = self.physics_prior(x)\n",
    "        \n",
    "        w = self.prior_weight.clamp(max=0.8)  # Cap at 80%\n",
    "        blended = w * prior + (1 - w) * learned\n",
    "        \n",
    "        return blended, {'prior': prior.mean().item(), 'learned': learned.mean().item(), 'weight': w.item()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Verify Prior Accuracy First\n",
    "\n",
    "Before comparing, let's check if the physics prior actually works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the physics prior alone\n",
    "prior = GravityPrior()\n",
    "\n",
    "with torch.no_grad():\n",
    "    prior_preds = prior(test_data.images)\n",
    "    prior_binary = (prior_preds.squeeze() > 0.5).float()\n",
    "    prior_acc = (prior_binary == test_data.labels).float().mean().item()\n",
    "\n",
    "print(f\"Physics Prior Accuracy (standalone): {prior_acc:.1%}\")\n",
    "print(f\"\")\n",
    "if prior_acc > 0.7:\n",
    "    print(\"Prior encodes useful physics knowledge!\")\n",
    "elif prior_acc > 0.55:\n",
    "    print(\"Prior has some signal but needs improvement\")\n",
    "else:\n",
    "    print(\"WARNING: Prior is not working correctly - check detection logic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_images, train_labels, epochs=100, lr=0.001, batch_size=32, verbose=False):\n",
    "    \"\"\"Train a model and return test accuracies during training.\"\"\"\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    n = len(train_labels)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        perm = torch.randperm(n)\n",
    "        total_loss = 0\n",
    "        \n",
    "        for i in range(0, n, batch_size):\n",
    "            idx = perm[i:min(i+batch_size, n)]\n",
    "            x = train_images[idx]\n",
    "            y = train_labels[idx].unsqueeze(1)\n",
    "            \n",
    "            # Forward\n",
    "            if isinstance(model, NSCAModel):\n",
    "                pred, _ = model(x)\n",
    "            else:\n",
    "                pred = model(x)\n",
    "            \n",
    "            loss = F.binary_cross_entropy(pred, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        if verbose and epoch % 20 == 0:\n",
    "            print(f\"  Epoch {epoch}: loss={total_loss/(n//batch_size):.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate(model, images, labels):\n",
    "    \"\"\"Evaluate model accuracy.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if isinstance(model, NSCAModel):\n",
    "            pred, info = model(images)\n",
    "        else:\n",
    "            pred = model(images)\n",
    "            info = {}\n",
    "        \n",
    "        pred_binary = (pred.squeeze() > 0.5).float()\n",
    "        acc = (pred_binary == labels).float().mean().item()\n",
    "    \n",
    "    return acc, info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Main Experiment: Sample Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"EXPERIMENT: Does Physics Prior Improve Sample Efficiency?\")\n",
    "print(\"=\"*70)\n",
    "print(\"\")\n",
    "print(\"Task: Predict if object will land on table from initial frame\")\n",
    "print(\"Physics knowledge needed: Objects fall straight down\")\n",
    "print(\"\")\n",
    "\n",
    "train_sizes = [20, 50, 100, 200, 500]\n",
    "n_seeds = 5\n",
    "epochs = 80\n",
    "\n",
    "results = {\n",
    "    'baseline': {n: [] for n in train_sizes},\n",
    "    'nsca': {n: [] for n in train_sizes}\n",
    "}\n",
    "\n",
    "for seed in range(n_seeds):\n",
    "    print(f\"\\n--- Seed {seed+1}/{n_seeds} ---\")\n",
    "    \n",
    "    for n_train in train_sizes:\n",
    "        # Subset training data\n",
    "        torch.manual_seed(seed * 1000 + n_train)\n",
    "        perm = torch.randperm(len(train_full.labels))[:n_train]\n",
    "        train_imgs = train_full.images[perm]\n",
    "        train_lbls = train_full.labels[perm]\n",
    "        \n",
    "        # Train baseline\n",
    "        torch.manual_seed(seed * 100 + n_train)\n",
    "        baseline = BaselineCNN()\n",
    "        baseline = train_model(baseline, train_imgs, train_lbls, epochs=epochs)\n",
    "        base_acc, _ = evaluate(baseline, test_data.images, test_data.labels)\n",
    "        results['baseline'][n_train].append(base_acc)\n",
    "        \n",
    "        # Train NSCA\n",
    "        torch.manual_seed(seed * 100 + n_train)\n",
    "        nsca = NSCAModel(initial_prior_weight=0.5)\n",
    "        nsca = train_model(nsca, train_imgs, train_lbls, epochs=epochs)\n",
    "        nsca_acc, info = evaluate(nsca, test_data.images, test_data.labels)\n",
    "        results['nsca'][n_train].append(nsca_acc)\n",
    "        \n",
    "        print(f\"N={n_train:3d}  Baseline: {base_acc:.1%}  NSCA: {nsca_acc:.1%}  (prior_w={info.get('weight', 0):.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESULTS: Sample Efficiency Comparison\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n{'N_train':<10} {'Baseline':<20} {'NSCA (w/ prior)':<20} {'Difference'}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "diffs = []\n",
    "for n in train_sizes:\n",
    "    base = np.array(results['baseline'][n])\n",
    "    nsca = np.array(results['nsca'][n])\n",
    "    diff = nsca.mean() - base.mean()\n",
    "    diffs.append(diff)\n",
    "    \n",
    "    print(f\"{n:<10} {base.mean():.1%} +/- {base.std():.1%}      {nsca.mean():.1%} +/- {nsca.std():.1%}      {diff:+.1%}\")\n",
    "\n",
    "print(\"-\"*70)\n",
    "print(f\"\\nAverage advantage in low-data (N<=100): {np.mean(diffs[:3]):+.1%}\")\n",
    "print(f\"Average advantage in high-data (N>100): {np.mean(diffs[3:]):+.1%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "if np.mean(diffs[:3]) > 0.03:\n",
    "    print(\"HYPOTHESIS SUPPORTED: Physics priors improve sample efficiency\")\n",
    "elif np.mean(diffs[:3]) > 0:\n",
    "    print(\"MARGINAL SUPPORT: Small advantage with priors\")\n",
    "else:\n",
    "    print(\"HYPOTHESIS NOT SUPPORTED in this configuration\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "x = np.array(train_sizes)\n",
    "\n",
    "base_means = [np.mean(results['baseline'][n]) for n in train_sizes]\n",
    "base_stds = [np.std(results['baseline'][n]) for n in train_sizes]\n",
    "nsca_means = [np.mean(results['nsca'][n]) for n in train_sizes]\n",
    "nsca_stds = [np.std(results['nsca'][n]) for n in train_sizes]\n",
    "\n",
    "plt.errorbar(x, base_means, yerr=base_stds, label='Baseline (no prior)', \n",
    "             marker='s', capsize=5, linewidth=2, markersize=8)\n",
    "plt.errorbar(x, nsca_means, yerr=nsca_stds, label='NSCA (with physics prior)', \n",
    "             marker='o', capsize=5, linewidth=2, markersize=8)\n",
    "\n",
    "# Prior-only baseline\n",
    "plt.axhline(y=prior_acc, color='gray', linestyle='--', label=f'Prior only ({prior_acc:.0%})')\n",
    "\n",
    "plt.xlabel('Number of Training Samples', fontsize=12)\n",
    "plt.ylabel('Test Accuracy', fontsize=12)\n",
    "plt.title('Sample Efficiency: Physics Prior on Stability Prediction', fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xscale('log')\n",
    "plt.ylim(0.4, 1.0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sample_efficiency_results.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analysis: Why Results Matter\n",
    "\n",
    "### If NSCA wins in low-data regime:\n",
    "- Physics prior provides useful inductive bias\n",
    "- \"Objects fall down\" knowledge transfers without learning\n",
    "- Validates the NSCA hypothesis\n",
    "\n",
    "### If Baseline catches up with more data:\n",
    "- Expected behavior: priors buy efficiency, not accuracy ceiling\n",
    "- Neural networks can learn physics from scratch with enough data\n",
    "\n",
    "### If Baseline wins everywhere:\n",
    "- Prior might not be accurate enough\n",
    "- Task might be too simple (visual shortcuts exist)\n",
    "- Need harder physics scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEXPERIMENT COMPLETE\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Try real Physion benchmark data\")\n",
    "print(\"2. Test with more complex physics (stacking, collisions)\")\n",
    "print(\"3. Measure prior weight adaptation over training\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
